import React, { useEffect, useRef, useState } from 'react';
import { GestureRecognizer, FilesetResolver, GestureRecognizerResult } from '@mediapipe/tasks-vision';
import { Loader2, AlertCircle } from 'lucide-react';
import { cn } from '../../lib/utils';

interface GestureControllerProps {
  onModeChange: (mode: 'tree' | 'heart' | 'scatter' | 'saturn' | 'flower' | 'dna' | 'sphere') => void;
  currentMode: 'tree' | 'heart' | 'scatter' | 'saturn' | 'flower' | 'dna' | 'sphere';
  isEnabled: boolean;
  setIsEnabled: (enabled: boolean) => void;
}

export const GestureController: React.FC<GestureControllerProps> = ({ onModeChange, currentMode, isEnabled, setIsEnabled }) => {
  const videoRef = useRef<HTMLVideoElement>(null);
  const [isModelLoading, setIsModelLoading] = useState(false);
  const [isModelLoaded, setIsModelLoaded] = useState(false);
  const [detectedGesture, setDetectedGesture] = useState<string>('');
  const [error, setError] = useState<string>('');
  const recognizerRef = useRef<GestureRecognizer | null>(null);
  const rafId = useRef<number | null>(null);
  const lastVideoTime = useRef<number>(-1);
  const streamRef = useRef<MediaStream | null>(null);
  const lastPredictionTime = useRef<number>(0);
  const predictionInterval = 200; // é™åˆ¶æ£€æµ‹é¢‘ç‡ä¸ºæ¯200msä¸€æ¬¡ (5fps)ï¼Œè§£å†³å¡é¡¿é—®é¢˜
  
    // Use ref to keep track of the latest callback and currentMode without triggering effect re-run
    const propsRef = useRef({ onModeChange, currentMode });
    useEffect(() => {
      propsRef.current = { onModeChange, currentMode };
    }, [onModeChange, currentMode]);

  // Load Model
  useEffect(() => {
    let mounted = true;

    const loadModel = async () => {
      if (recognizerRef.current) return;
      
      try {
        setIsModelLoading(true);
        setError('');
        
        const vision = await FilesetResolver.forVisionTasks(
          "https://resource-static.cdn.bcebos.com/common/task-vision"
        );
        
        if (!mounted) return;

        const recognizer = await GestureRecognizer.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: "https://resource-static.cdn.bcebos.com/common/gesture_recognizer.task",
            delegate: "GPU"
          },
          runningMode: "VIDEO",
          numHands: 2, // å¯ç”¨åŒæ‰‹æ£€æµ‹
          minHandDetectionConfidence: 0.5,
          minHandPresenceConfidence: 0.5,
          minTrackingConfidence: 0.5
        });

        if (mounted) {
          recognizerRef.current = recognizer;
          setIsModelLoaded(true);
          setIsModelLoading(false);
        }
      } catch (error) {
        console.error("åŠ è½½æ‰‹åŠ¿è¯†åˆ«æ¨¡å‹å¤±è´¥:", error);
        if (mounted) {
          setIsModelLoading(false);
          setError('æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·åˆ·æ–°é‡è¯•');
          setIsEnabled(false);
        }
      }
    };

    if (isEnabled && !isModelLoaded && !recognizerRef.current) {
      loadModel();
    }

    return () => {
      mounted = false;
    };
  }, [isEnabled, isModelLoaded, setIsEnabled]);

  // Handle Camera & Detection Loop
  useEffect(() => {
    if (!isEnabled || !recognizerRef.current || !videoRef.current) {
      // Clean up if disabled
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
        streamRef.current = null;
      }
      if (rafId.current) {
        cancelAnimationFrame(rafId.current);
        rafId.current = null;
      }
      return;
    }

    const startCamera = async () => {
      try {
        setError('');
        const stream = await navigator.mediaDevices.getUserMedia({ 
          video: { 
            facingMode: 'user'
            // ç§»é™¤ç¡¬ç¼–ç çš„åˆ†è¾¨ç‡é™åˆ¶ï¼Œæé«˜æ‰‹æœºå…¼å®¹æ€§
          } 
        });
        
        streamRef.current = stream;
        
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
          // Wait for video to be ready
          videoRef.current.onloadedmetadata = () => {
            videoRef.current?.play().then(() => {
              predictWebcam();
            }).catch(err => {
              console.error("è§†é¢‘æ’­æ”¾å¤±è´¥:", err);
              setError('è§†é¢‘æ’­æ”¾å¤±è´¥');
            });
          };
        }
      } catch (err) {
        console.error("æ‘„åƒå¤´è®¿é—®å¤±è´¥:", err);
        const errorMsg = err instanceof Error ? err.message : String(err);
        if (errorMsg.includes('Permission denied') || errorMsg.includes('NotAllowedError')) {
          setError('æ‘„åƒå¤´æƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸è®¿é—®');
        } else if (errorMsg.includes('NotFoundError')) {
          setError('æœªæ‰¾åˆ°æ‘„åƒå¤´è®¾å¤‡');
        } else {
          setError('æ‘„åƒå¤´å¯åŠ¨å¤±è´¥: ' + errorMsg);
        }
        setIsEnabled(false);
      }
    };

    const predictWebcam = () => {
    if (!videoRef.current || !recognizerRef.current || !isEnabled) return;

    const video = videoRef.current;
    
    // Check if video is ready
    if (video.readyState < 2) {
      rafId.current = requestAnimationFrame(predictWebcam);
      return;
    }

    const now = Date.now();
    // èŠ‚æµæ§åˆ¶ï¼šåªæœ‰è·ç¦»ä¸Šæ¬¡æ£€æµ‹è¶…è¿‡ predictionInterval æ‰æ‰§è¡Œ
    if (now - lastPredictionTime.current >= predictionInterval) {
      if (video.currentTime !== lastVideoTime.current) {
        lastVideoTime.current = video.currentTime;
        lastPredictionTime.current = now;
        
        try {
          const results = recognizerRef.current.recognizeForVideo(video, now);
          processResults(results);
        } catch (e) {
          console.error("æ‰‹åŠ¿è¯†åˆ«é”™è¯¯:", e);
        }
      }
    }
    
    rafId.current = requestAnimationFrame(predictWebcam);
  };

    startCamera();

    return () => {
      if (rafId.current) {
        cancelAnimationFrame(rafId.current);
        rafId.current = null;
      }
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
        streamRef.current = null;
      }
    };
  }, [isEnabled, isModelLoaded, setIsEnabled]);

  const processResults = (results: GestureRecognizerResult) => {
    if (results.gestures.length > 0) {
      // ä¼˜å…ˆæ£€æµ‹åŒæ‰‹ç»„åˆæ‰‹åŠ¿
      if (results.gestures.length === 2) {
        const gesture1 = results.gestures[0][0].categoryName;
        const gesture2 = results.gestures[1][0].categoryName;
        const score1 = results.gestures[0][0].score;
        const score2 = results.gestures[1][0].score;

        // åŒæ‰‹æŒ‡å¤© -> DNA
        if (score1 > 0.6 && score2 > 0.6 && 
            gesture1 === 'Pointing_Up' && gesture2 === 'Pointing_Up') {
          setDetectedGesture('Dual_Point');
          const { onModeChange } = propsRef.current;
          onModeChange('dna');
          return; // ä¼˜å…ˆå¤„ç†åŒæ‰‹ï¼Œä¸å†å¤„ç†å•æ‰‹
        }
      }

      // å•æ‰‹é€»è¾‘ (æˆ–è€…åŒæ‰‹ä½†ä¸æ»¡è¶³ç‰¹å®šç»„åˆæ—¶ï¼Œå–ç½®ä¿¡åº¦æœ€é«˜çš„æ‰‹åŠ¿)
      // æ‰¾å‡ºç½®ä¿¡åº¦æœ€é«˜çš„æ‰‹åŠ¿
      let bestGesture = results.gestures[0][0];
      for (let i = 1; i < results.gestures.length; i++) {
        if (results.gestures[i][0].score > bestGesture.score) {
          bestGesture = results.gestures[i][0];
        }
      }

      const category = bestGesture.categoryName;
      const score = bestGesture.score;

      if (score > 0.6) {
        setDetectedGesture(category);
        
        const { onModeChange } = propsRef.current;

        // Map gestures to modes
        if (category === 'Open_Palm') {
          onModeChange('scatter');
        } else if (category === 'Closed_Fist') {
          onModeChange('tree');
        } else if (category === 'Victory') {
          onModeChange('heart');
        } else if (category === 'Pointing_Up') {
          onModeChange('flower'); // æ¢å¤ä¸ºåªè§¦å‘èŠ±æœµ
        } else if (category === 'ILoveYou') {
          onModeChange('saturn');
        } else if (category === 'Thumb_Down') {
          onModeChange('sphere');
        }
        // Removed Thumb_Up completely
      }
    } else {
      // Don't clear immediately to avoid flickering text?
      // setDetectedGesture(''); 
      // Actually clearing is fine for UI feedback
      setDetectedGesture('');
    }
  };

  if (!isEnabled) return null;

  return (
    <div className="absolute bottom-4 right-4 z-40 flex flex-col items-end gap-2 animate-in fade-in slide-in-from-bottom-10 duration-500">
      {/* Error State */}
      {error && (
        <div className="bg-red-900/80 backdrop-blur-md px-3 py-2 rounded-lg border border-red-500/50 text-red-100 flex items-start gap-2 max-w-[200px]">
          <AlertCircle className="w-4 h-4 flex-shrink-0 mt-0.5" />
          <div className="text-[10px]">
            <p className="font-bold mb-0.5">é”™è¯¯</p>
            <p>{error}</p>
          </div>
        </div>
      )}

      {/* Loading State */}
      {isModelLoading && (
        <div className="bg-black/60 backdrop-blur-md px-3 py-1.5 rounded-lg border border-white/10 text-emerald-100 flex items-center gap-2">
          <Loader2 className="animate-spin w-3 h-3" />
          <span className="text-[10px]">åŠ è½½æ¨¡å‹...</span>
        </div>
      )}

      {/* Video Preview - Miniaturized */}
      <div className={cn(
        "relative w-24 h-24 bg-black/50 rounded-lg overflow-hidden border border-white/10 shadow-lg transition-all hover:scale-150 origin-bottom-right group", // Default very small, hover to enlarge
        isModelLoaded && !error ? "opacity-100" : "opacity-0"
      )}>
        <video 
          ref={videoRef}
          autoPlay 
          playsInline
          muted
          className="w-full h-full object-cover -scale-x-100 opacity-80 group-hover:opacity-100 transition-opacity" // Slightly transparent by default
        />
        
        {/* Gesture Indicator overlay - Compact */}
        <div className="absolute bottom-0 left-0 right-0 bg-black/70 backdrop-blur-[2px] p-1 text-center">
          <span className="text-[10px] font-mono text-emerald-400 font-bold block truncate">
            {detectedGesture ? detectedGesture : "ç­‰å¾…æ‰‹åŠ¿"}
          </span>
        </div>
      </div>

      {/* Helper Text - Minimalist & Compact */}
      {isModelLoaded && !error && (
        <div className="fixed bottom-4 left-4 z-50 text-emerald-100/70 transition-opacity duration-500 select-none pointer-events-none origin-bottom-left scale-[0.6] sm:scale-100">
          <div className="flex flex-col gap-1">
            <h3 className="font-bold text-xs text-emerald-500/50 mb-0.5 uppercase tracking-widest hidden sm:block">Gesture Guide</h3>
            <div className="grid grid-cols-2 gap-x-2 gap-y-0.5 text-[10px] sm:text-[11px] font-mono">
               <span className="flex items-center gap-1.5 whitespace-nowrap"><span className="text-sm grayscale opacity-70">ğŸ‘‹</span> <span>æ‰“æ•£</span></span>
               <span className="flex items-center gap-1.5 whitespace-nowrap"><span className="text-sm grayscale opacity-70">âœŠ</span> <span>2026</span></span>
               <span className="flex items-center gap-1.5 whitespace-nowrap"><span className="text-sm grayscale opacity-70">âœŒï¸</span> <span>çˆ±å¿ƒ</span></span>
               <span className="flex items-center gap-1.5 whitespace-nowrap"><span className="text-sm grayscale opacity-70">ğŸ¤Ÿ</span> <span>åœŸæ˜Ÿ</span></span>
               <span className="flex items-center gap-1.5 whitespace-nowrap"><span className="text-sm grayscale opacity-70">â˜ï¸</span> <span>èŠ±æœµ</span></span>
               <span className="flex items-center gap-1.5 whitespace-nowrap"><span className="text-sm grayscale opacity-70">â˜ï¸â˜ï¸</span> <span>DNA</span></span>
               <span className="flex items-center gap-1.5 whitespace-nowrap"><span className="text-sm grayscale opacity-70">ğŸ‘</span> <span>çƒä½“</span></span>
            </div>
          </div>
        </div>
      )}
    </div>
  );
};